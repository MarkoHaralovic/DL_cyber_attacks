{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning defense\n",
    "\n",
    "Prune an EfficientNetv2 model that has been pretrained on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = os.path.join(\"..\", \"datasets\")\n",
    "CIFAR_DIR = os.path.join(DATASETS_DIR, \"CIFAR10\", \"cifar-10\")\n",
    "\n",
    "MODEL_NAME = 'efficientnet_v2_s'\n",
    "WEIGHT_PATH = os.path.join(\"..\", \"models\", \"efficientnet_v2_s_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load locally stored CIFAR-10\n",
    "\n",
    "We'll just be using the clean dataset for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.path.join(CIFAR_DIR, \"train\", \"data.npy\")\n",
    "train_labels = os.path.join(CIFAR_DIR, \"train\", \"labels.npy\")\n",
    "test_images = os.path.join(CIFAR_DIR, \"test\", \"data.npy\")\n",
    "test_labels = os.path.join(CIFAR_DIR, \"test\", \"labels.npy\")\n",
    "\n",
    "cifar_10_dataset= Data(train_images=train_images,train_labels=train_labels,\n",
    "                     test_images=test_images,test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar_10_dataset.normalize()\n",
    "cifar_10_dataset.show_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.hub.load('hankyul2/EfficientNetV2-pytorch', MODEL_NAME, nclass=cifar_10_dataset.num_classes, skip_validation=False)\n",
    "model.to(device)\n",
    "\n",
    "state_dict = torch.load(WEIGHT_PATH)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize activations of ~~the last convolutional layer~~ any layer\n",
    "\n",
    "> \"Later convolutional layers in a DNN sparsely encode the features learned in earlier layers, so pruning neurons in the later layers has a larger impact on the behavior of the network. Consequently, **we prune only the last convolutional layer**...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available layers\n",
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_WEIGHT_KEY = 'blocks.0.block.fused.0.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights = model.state_dict()[SELECTED_WEIGHT_KEY]\n",
    "\n",
    "layer_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only visualize the first out of 24 channels\n",
    "\n",
    "grid = make_grid(layer_weights[:,:1,:,:], pad_value=1)\n",
    "np_grid = grid.cpu().numpy()\n",
    "plt.imshow(np.transpose(np_grid, (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on test dataset (measure accuracy) for comparison after pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split,TensorDataset\n",
    "from torchvision import transforms \n",
    "from torchvision.transforms import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_10_dataset.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.tensor(cifar_10_dataset.test_images, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "test_labels = torch.tensor(cifar_10_dataset.test_labels, dtype=torch.long)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()  \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    i = 0\n",
    "    resize_transform = transforms.Resize((224, 224), antialias=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader):\n",
    "            # Resize images here if facing memory issues with whole dataset reshaped at once\n",
    "            images = torch.stack([resize_transform(img) for img in images])\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            i = i + 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_model(model, test_loader, device)\n",
    "print(f'Test Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune last convolutional layer in Efficient Net and evaluate new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "prune_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(cifar_10_dataset.train_images, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "train_labels = torch.tensor(cifar_10_dataset.train_labels, dtype=torch.long)\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                               num_workers=8 ,\n",
    "                               drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_prune = None\n",
    "for name, module in model.named_modules():\n",
    "    if name == 'blocks.39.block.depth_wise.0':\n",
    "        layer_to_prune = module\n",
    "        break\n",
    "\n",
    "if layer_to_prune is None:\n",
    "    raise AttributeError(\"Layer 'blocks.39.block.depth_wise.0' not found in the model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Layer to prune:\", layer_to_prune)\n",
    "print(\"======== pruning... ========\")\n",
    "with torch.no_grad():\n",
    "   container = []\n",
    "   def forward_hook(module, input, output):\n",
    "      container.append(output)\n",
    "   #hook = getattr(model, layer_to_prune).register_forward_hook(forward_hook)\n",
    "   hook = layer_to_prune.register_forward_hook(forward_hook)\n",
    "   print(\"Forwarding all training set\")\n",
    "   model.eval()\n",
    "   for data, _ in tr_loader:\n",
    "      if device ==\"cuda\":\n",
    "         model(data.cuda())\n",
    "      else:\n",
    "         model(data)\n",
    "   hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_copy = container\n",
    "print(container==container_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_outputs = [torch.squeeze(output) for output in container]\n",
    "container_squeezed =  torch.cat(squeezed_outputs, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container_squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = torch.cat(container, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = torch.mean(container, dim=[0, 2, 3])\n",
    "# activation = torch.mean(container_squeezed)\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_sort = torch.argsort(activation)\n",
    "print(seq_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = len(activation)\n",
    "print(num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunned_channels = int(num_channels * prune_rate)\n",
    "mask = torch.ones(num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in seq_sort[:prunned_channels]:\n",
    "   mask[element] = 0\n",
    "if len(container.shape) == 4:\n",
    "   mask = mask.reshape(1, -1, 1, 1)\n",
    "   \n",
    "if len(layer_to_prune.weight.data.shape) == 4:\n",
    "    mask = mask.view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_prune.weight.data *= mask\n",
    "model = model\n",
    "print(\"======== pruning complete ========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_model(model, test_loader, device)\n",
    "print(f'Test Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
